{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. WEEK 3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds= tf.data.Dataset.from_tensor_slices(z) \n",
    "# SLICE Z THEO AXIS = 0: Matran2D thanh cac dong, 1D thành cách phần tử\n",
    "# Kết quả là 1 list của tube\n",
    "\n",
    "dataset1.element_spec  # kiểm tra kiểu của phần tử"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset3 = tf.data.Dataset.zip((ds1, ds2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = tf.data.Dataset.from_tensor_slices((images_numpy, labels_numpy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "flowers_root = tf.keras.utils.get_file(\n",
    "    'flower_photos',\n",
    "    'https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz',\n",
    "    untar=True)\n",
    "flowers_root = pathlib.Path(flowers_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ds = tf.data.Dataset.list_files(str(flowers_root/'*/*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads an image from a file, decodes it into a dense tensor, and resizes it\n",
    "# to a fixed shape.\n",
    "def parse_image(filename):\n",
    "  parts = tf.strings.split(filename, '/')\n",
    "  label = parts[-2]\n",
    "\n",
    "  image = tf.io.read_file(filename)\n",
    "  image = tf.image.decode_jpeg(image)\n",
    "  image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "  image = tf.image.resize(image, [128, 128])\n",
    "  return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = next(iter(list_ds))\n",
    "image, label = parse_image(file_path)\n",
    "\n",
    "def show(image, label):\n",
    "  plt.figure()\n",
    "  plt.imshow(image)\n",
    "  plt.title(label.numpy().decode('utf-8'))\n",
    "  plt.axis('off')\n",
    "\n",
    "show(image, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_ds = list_ds.map(parse_image)\n",
    "\n",
    "for image, label in images_ds.take(2):\n",
    "  show(image, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. WEEK 1-2a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tfds.list_builder()) # all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXTRACT 1\n",
    "data = tfds.load('horses_or_humans', split='train'|'test'|['train', 'split']|'train[:5000|20%]'||| 'train+test'#merger\n",
    "                 , as_supervised=True)\n",
    "val_data = tfds.load('horses_or_humans', split='test', as_supervised=True)\n",
    "# chọn key 'train'\n",
    "#with_info = True --> xem tất cả info (tfds.medatada) --kết quả là (dataset, info) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXTRACT 2: K_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds = tfds.load('mnist:3.*.*', split=['train[{}%:{}%]'.format(k, k+20) for k in range(0, 100, 20)])\n",
    "train_ds = tfds.load('mnist:3.*.*', split=['train[:{}%]+train[{}%:]'.format(k, k+20) for k in range(0, 100, 20)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1, s2, s3, s4 = tfds.Split.TRAIN.subsplit(k=4)\n",
    "\n",
    "dataset_split_1 = tfds.load(\"mnist\", split=s1)\n",
    "dataset_split_2 = tfds.load(\"mnist\", split=s2)\n",
    "dataset_split_3 = tfds.load(\"mnist\", split=s3)\n",
    "dataset_split_4 = tfds.load(\"mnist\", split=s4)\n",
    "\n",
    "print(len(list(dataset_split_1)))\n",
    "print(len(list(dataset_split_2)))\n",
    "print(len(list(dataset_split_3)))\n",
    "print(len(list(dataset_split_4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRANSFORM\n",
    "dataset.shuffle(100)\n",
    "\n",
    "# LOAD\n",
    "for data in dataset.take(1):\n",
    "    image = data[\"image\"].numpy().squeeze()\n",
    "    label = data[\"label\"].numpy()\n",
    "    \n",
    "    print(\"Label: {}\".format(label))\n",
    "    plt.imshow(image, cmap=plt.cm.binary)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. WEEK 2b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename=\"/root/tensorflow_datasets/mnist/3.0.0/mnist-test.tfrecord-00000-of-00001\"\n",
    "raw_dataset = tf.data.TFRecordDataset(filename)\n",
    "for raw_record in raw_dataset.take(1):\n",
    "    print(repr(raw_record))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a description of the features.\n",
    "feature_description = {\n",
    "    'image': tf.io.FixedLenFeature([], dtype=tf.string),\n",
    "    'label': tf.io.FixedLenFeature([], dtype=tf.int64),\n",
    "}\n",
    "\n",
    "def _parse_function(example_proto):\n",
    "  # Parse the input `tf.Example` proto using the dictionary above.\n",
    "  return tf.io.parse_single_example(example_proto, feature_description)\n",
    "\n",
    "parsed_dataset = raw_dataset.map(_parse_function)\n",
    "for parsed_record in parsed_dataset.take(1):\n",
    "    print((parsed_record))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. WEEK 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = tf.data.Dataset.from_generator(\n",
    "    img_gen.flow_from_directory, args=[flowers], \n",
    "    output_types=(tf.float32, tf.float32), \n",
    "    output_shapes=([32,256,256,3], [32,5])\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf]",
   "language": "python",
   "name": "conda-env-tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
